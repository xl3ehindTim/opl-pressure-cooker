{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import ast\n",
    "import warnings\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"rounakbanik/pokemon\")\n",
    "df = pd.read_csv(path + \"/pokemon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['japanese_name', 'capture_rate', 'generation', 'percentage_male', 'pokedex_number', 'base_egg_steps'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Create a copy of the dataframe\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Convert abilities from string representation of list to actual list\n",
    "    df_processed['abilities'] = df_processed['abilities'].apply(ast.literal_eval)\n",
    "    \n",
    "    # Create separate rows for each ability\n",
    "    df_exploded = df_processed.explode('abilities')\n",
    "    \n",
    "    # Handle missing values - important: add 'none' to types list\n",
    "    df_exploded['type2'].fillna('none', inplace=True)\n",
    "    df_exploded['weight_kg'].fillna(df_exploded['weight_kg'].mean(), inplace=True)\n",
    "    df_exploded['height_m'].fillna(df_exploded['height_m'].mean(), inplace=True)\n",
    "    \n",
    "    # Get unique values first, ensuring 'none' is included in types\n",
    "    unique_types = sorted(set(df_exploded['type1'].unique()) | set(df_exploded['type2'].unique()) | {'none'})\n",
    "    unique_abilities = sorted(df_exploded['abilities'].unique())\n",
    "\n",
    "    \n",
    "    # Create label encoders\n",
    "    le_type = LabelEncoder().fit(unique_types)\n",
    "    le_ability = LabelEncoder().fit(unique_abilities)\n",
    "    \n",
    "    # Encode values\n",
    "    df_exploded['type1_encoded'] = le_type.transform(df_exploded['type1'])\n",
    "    df_exploded['type2_encoded'] = le_type.transform(df_exploded['type2'])\n",
    "    df_exploded['ability_encoded'] = le_ability.transform(df_exploded['abilities'])\n",
    "\n",
    "    \n",
    "    return df_exploded, len(unique_types), len(unique_abilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokemonTypeTransformer(nn.Module):\n",
    "    def __init__(self, n_types, n_abilities, d_model=32, nhead=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embeddings\n",
    "        self.type_embedding = nn.Embedding(n_types, d_model)\n",
    "        self.ability_embedding = nn.Embedding(n_abilities, d_model)\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=128,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Output projection to ensure consistent size\n",
    "        self.output_projection = nn.Linear(d_model * 6, d_model)  # 6 = 2*type1 + 2*type2 + 2*ability\n",
    "        \n",
    "    def forward(self, type_ids, ability_ids):\n",
    "        # Get embeddings\n",
    "        type_emb = self.type_embedding(type_ids)  # Shape: [batch, 2, d_model]\n",
    "        ability_emb = self.ability_embedding(ability_ids)  # Shape: [batch, 2, d_model]\n",
    "        \n",
    "        # Flatten embeddings\n",
    "        batch_size = type_emb.size(0)\n",
    "        type_emb_flat = type_emb.reshape(batch_size, -1)  # Shape: [batch, 2*d_model]\n",
    "        ability_emb_flat = ability_emb.reshape(batch_size, -1)  # Shape: [batch, 2*d_model]\n",
    "\n",
    "        # Concatenate all embeddings\n",
    "        x = torch.cat([type_emb_flat, ability_emb_flat], dim=1)  # Shape: [batch, 4*d_model]\n",
    "\n",
    "        # Project to desired output size\n",
    "        x = self.output_projection(x)  # Shape: [batch, d_model]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokemonCounterPredictor(nn.Module):\n",
    "    def __init__(self, type_transformer, input_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.type_transformer = type_transformer\n",
    "        \n",
    "        # Calculate input size for the predictor\n",
    "        transformer_output_size = 32  # d_model from transformer\n",
    "        stats_size = 48  # number of stat features (24 * 2 for both Pokemon)\n",
    "        total_input_size = transformer_output_size + stats_size\n",
    "        \n",
    "        # Neural network for counter prediction\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(total_input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, type1_ids, type2_ids, ability_ids, stats):\n",
    "\n",
    "        pokemon_emb = self.type_transformer(\n",
    "            torch.cat([type1_ids, type2_ids], dim=1),  # Shape: [batch, 4]\n",
    "            ability_ids  # Shape: [batch, 2]\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Combine with stats\n",
    "        x = torch.cat([pokemon_emb, stats], dim=1)\n",
    "\n",
    "        # Predict\n",
    "        return self.predictor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_effectiveness(attacker, defender):\n",
    "    # Map type names to their corresponding column names\n",
    "    type_map = {\n",
    "        'fighting': 'fight'  # Add any other mappings if needed\n",
    "    }\n",
    "    \n",
    "    # Calculate type effectiveness for type1\n",
    "    type1_col = 'against_' + (type_map.get(attacker['type1'].lower(), attacker['type1'].lower()))\n",
    "    type_effectiveness = defender[type1_col]\n",
    "    \n",
    "    # Calculate type effectiveness for type2 if it exists\n",
    "    if attacker['type2'] != 'none':\n",
    "        type2_col = 'against_' + (type_map.get(attacker['type2'].lower(), attacker['type2'].lower()))\n",
    "        type_effectiveness *= defender[type2_col]\n",
    "    \n",
    "    # Calculate stat-based effectiveness\n",
    "    stat_effectiveness = (\n",
    "        attacker['attack'] + attacker['sp_attack'] + attacker['speed']\n",
    "    ) / (\n",
    "        defender['defense'] + defender['sp_defense'] + defender['hp']\n",
    "    )\n",
    "    \n",
    "    return type_effectiveness * stat_effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokemonDataset(Dataset):\n",
    "    def __init__(self, df_processed):\n",
    "        self.data = df_processed\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        numerical_cols = ['attack', 'defense', 'sp_attack', 'sp_defense', 'speed', 'hp',\n",
    "                         'against_bug', 'against_dark', 'against_dragon', 'against_electric',\n",
    "                         'against_fairy', 'against_fight', 'against_fire', 'against_flying',\n",
    "                         'against_ghost', 'against_grass', 'against_ground', 'against_ice',\n",
    "                         'against_normal', 'against_poison', 'against_psychic', 'against_rock',\n",
    "                         'against_steel', 'against_water']\n",
    "        \n",
    "        self.stats = self.scaler.fit_transform(self.data[numerical_cols])\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) * 5\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx1 = idx % len(self.data)\n",
    "        idx2 = np.random.randint(0, len(self.data))\n",
    "        \n",
    "        pokemon1 = self.data.iloc[idx1]\n",
    "        pokemon2 = self.data.iloc[idx2]\n",
    "        \n",
    "        # Calculate effectiveness\n",
    "        effectiveness1 = calculate_effectiveness(pokemon1, pokemon2)\n",
    "        effectiveness2 = calculate_effectiveness(pokemon2, pokemon1)\n",
    "        \n",
    "        # Prepare inputs with correct shapes\n",
    "        type1_ids = torch.tensor([pokemon1['type1_encoded'], pokemon2['type1_encoded']])\n",
    "        type2_ids = torch.tensor([pokemon1['type2_encoded'], pokemon2['type2_encoded']])\n",
    "        ability_ids = torch.tensor([pokemon1['ability_encoded'], pokemon2['ability_encoded']])\n",
    "\n",
    "        \n",
    "        stats = torch.FloatTensor(np.concatenate([\n",
    "            self.stats[idx1],\n",
    "            self.stats[idx2]\n",
    "        ]))\n",
    "        \n",
    "        target = torch.FloatTensor([1.0 if effectiveness1 > effectiveness2 else 0.0])\n",
    "        \n",
    "        return type1_ids, type2_ids, ability_ids, stats, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, num_epochs=10, learning_rate=0.001):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for type1_ids, type2_ids, ability_ids, stats, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(type1_ids, type2_ids, ability_ids, stats)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            predictions = (outputs >= 0.5).float()\n",
    "            correct += (predictions == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "        \n",
    "        epoch_loss = total_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_and_train():\n",
    "    # Preprocess data\n",
    "    global df_processed, dataset\n",
    "    df_processed, n_types, n_abilities = preprocess_data(df)\n",
    "\n",
    "    \n",
    "    # Create models with correct sizes\n",
    "    type_transformer = PokemonTypeTransformer(n_types, n_abilities)\n",
    "    model = PokemonCounterPredictor(\n",
    "        type_transformer,\n",
    "        input_size=32 + 48  # 32 from transformer + 48 stats features\n",
    "    )\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = PokemonDataset(df_processed)\n",
    "    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Train\n",
    "    train_model(model, train_loader)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_counter_transformer(model, pokemon_name, ability, df_processed):\n",
    "    # Get Pokemon data\n",
    "    pokemon = df_processed[df_processed['name'] == pokemon_name].iloc[0]\n",
    "    \n",
    "    # Prepare inputs for all possible counters\n",
    "    all_counters = []\n",
    "    for _, counter in df_processed.iterrows():\n",
    "        type1_ids = torch.tensor([pokemon['type1_encoded'], counter['type1_encoded']])\n",
    "        type2_ids = torch.tensor([pokemon['type2_encoded'], counter['type2_encoded']])\n",
    "        ability_ids = torch.tensor([pokemon['ability_encoded'], counter['ability_encoded']])\n",
    "        \n",
    "        stats = torch.FloatTensor(np.concatenate([\n",
    "            dataset.stats[pokemon.name],\n",
    "            dataset.stats[counter.name]\n",
    "        ]))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            score = model(type1_ids.unsqueeze(0), type2_ids.unsqueeze(0), \n",
    "                         ability_ids.unsqueeze(0), stats.unsqueeze(0))\n",
    "        \n",
    "        all_counters.append((counter['name'], counter['abilities'], score.item()))\n",
    "    \n",
    "    # Sort by score and get top 5\n",
    "    all_counters.sort(key=lambda x: x[2], reverse=True)\n",
    "    return all_counters[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "Loss: 0.4910, Accuracy: 0.7629\n",
      "Epoch 2/10:\n",
      "Loss: 0.3942, Accuracy: 0.8162\n",
      "Epoch 3/10:\n",
      "Loss: 0.3433, Accuracy: 0.8504\n",
      "Epoch 4/10:\n",
      "Loss: 0.3161, Accuracy: 0.8571\n",
      "Epoch 5/10:\n",
      "Loss: 0.2901, Accuracy: 0.8729\n",
      "Epoch 6/10:\n",
      "Loss: 0.2731, Accuracy: 0.8764\n",
      "Epoch 7/10:\n",
      "Loss: 0.2615, Accuracy: 0.8858\n",
      "Epoch 8/10:\n",
      "Loss: 0.2438, Accuracy: 0.8947\n",
      "Epoch 9/10:\n",
      "Loss: 0.2391, Accuracy: 0.8958\n",
      "Epoch 10/10:\n",
      "Loss: 0.2263, Accuracy: 0.9008\n"
     ]
    }
   ],
   "source": [
    "model = initialize_and_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_form():\n",
    "    pokemon_list = sorted(df['name'].unique())\n",
    "    pokemon_dropdown = widgets.Dropdown(\n",
    "        options=pokemon_list,\n",
    "        description='Pokemon:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_pokemon_select(change):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            selected_pokemon = change.new\n",
    "            predictions = predict_counter_transformer(model, selected_pokemon, None, df_processed)\n",
    "            print(f\"\\nBest counters for {selected_pokemon}:\")\n",
    "            for name, abilities, score in predictions:\n",
    "                print(f\"- {name} (Score: {score:.3f})\")\n",
    "                print(f\"  Abilities: {''.join(abilities)}\")\n",
    "    \n",
    "    pokemon_dropdown.observe(on_pokemon_select, names='value')\n",
    "    \n",
    "    form = widgets.VBox([\n",
    "        pokemon_dropdown,\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    display(form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdd55f819e44434bac8200474020fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Pokemon:', options=('Abomasnow', 'Abra', 'Absol', 'Accelgor', 'Aegislash'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_prediction_form()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
